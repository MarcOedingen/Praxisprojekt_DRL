{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN1zDdiI91RT"
      },
      "source": [
        "pip install stable-baselines3[extra]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e40qZheh98pv"
      },
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "import gym\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfMXudKp-eZL"
      },
      "source": [
        "log_name = \"DQN_CartPole-v1_TensorBoard\"\n",
        "path = f\"/content/{log_name}\"\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "policy_kwargs=dict(net_arch=[256, 256])\n",
        "model = DQN(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, learning_rate=0.001,batch_size=64, buffer_size=100000, learning_starts=500, target_update_interval=10, train_freq=256, gradient_steps=50, exploration_fraction=0.16, exploration_final_eps=0.04, verbose=1, tensorboard_log=f\"./{log_name}/\")\n",
        "model.learn(total_timesteps=5e4)\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "%tensorboard --logdir /content/DQN_CartPole-v1_TensorBoard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjiLJDnKqR1s"
      },
      "source": [
        "log_name = \"DQN_MountainCar-v0_TensorBoard\"\n",
        "path = f\"/content/{log_name}\"\n",
        "env = gym.make(\"MountainCar-v0\")\n",
        "policy_kwargs=dict(net_arch=[256, 256])\n",
        "model = DQN(\"MlpPolicy\",env, policy_kwargs=policy_kwargs, verbose=1, learning_rate=0.004, batch_size=128, buffer_size=10000, learning_starts=1000, gamma=0.98, target_update_interval=600, train_freq=16, gradient_steps=8, exploration_fraction=0.2, exploration_final_eps=0.07, tensorboard_log=f\"./{log_name}/\")\n",
        "model.learn(total_timesteps=120000)\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "%tensorboard --logdir /content/DQN_MountainCar-v0_TensorBoard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73JQrl0yoFEd"
      },
      "source": [
        "log_name = \"DQN_Acrobot-v1_TensorBoard\"\n",
        "path = f\"/content/{log_name}\"\n",
        "env = gym.make(\"Acrobot-v1\")\n",
        "policy_kwargs=dict(net_arch=[256, 256])\n",
        "model = DQN(\"MlpPolicy\",env, policy_kwargs=policy_kwargs, verbose=1, learning_rate=0.00063, batch_size=128, buffer_size=50000, learning_starts=0, gamma=0.99, target_update_interval=250, train_freq=4, gradient_steps=-1, exploration_fraction=0.12, exploration_final_eps=0.1, tensorboard_log=f\"./{log_name}/\")\n",
        "model.learn(total_timesteps=100000)\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "%tensorboard --logdir /content/DQN_Acrobot-v1_TensorBoard"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}